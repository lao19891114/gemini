import streamlit as st
import google.generativeai as genai
import os

# é¡µé¢åŸºç¡€è®¾ç½®
st.set_page_config(page_title="Gemini ç§äººç©ºé—´", page_icon="ğŸŒ™")
st.title("Gemini 3 Pro - æ²‰æµ¸å¼å†™ä½œ (CNç›´è¿ç‰ˆ)")

# ä»ç¯å¢ƒå˜é‡è·å– Key (é€‚é… Zeabur)
api_key = os.getenv("GOOGLE_API_KEY")

# å¦‚æœæœ¬åœ°æµ‹è¯•æ²¡æœ‰ç¯å¢ƒå˜é‡ï¼Œå°è¯•ä» Streamlit Secrets è·å–ï¼ˆå…¼å®¹ Streamlit Cloudï¼‰
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        pass

if not api_key:
    st.error("è¯·é…ç½® API Keyï¼(åœ¨ Zeabur çš„ Variables ä¸­æ·»åŠ  GOOGLE_API_KEY)")
    st.stop()

# é…ç½® API
genai.configure(api_key=api_key)

# ã€æ ¸å¿ƒã€‘æš´åŠ›è§£é”å®‰å…¨è®¾ç½® (Block None)
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# åˆå§‹åŒ–æ¨¡å‹å‡½æ•°
def get_model(model_name):
    generation_config = {
        "temperature": 1.0, # ç¨å¾®è°ƒé«˜ï¼Œå¢åŠ åˆ›é€ æ€§
        "max_output_tokens": 8192,
    }
    return genai.GenerativeModel(
        model_name=model_name,
        generation_config=generation_config,
        safety_settings=safety_settings
    )

# èŠå¤©ç•Œé¢é€»è¾‘
if "messages" not in st.session_state:
    st.session_state.messages = []

# ä¾§è¾¹æ ï¼šé€‰æ‹©æ¨¡å‹
with st.sidebar:
    st.header("æ¨¡å‹é€‰æ‹©")
    selected_model = st.selectbox(
        "é€‰æ‹©ä½ çš„å†™æ‰‹:",
        ["gemini-1.5-flash", "gemini-2.0-flash-exp", "gemini-1.5-pro"],
        index=0
    )
    st.info("ğŸ’¡ æç¤ºï¼šFlash é€Ÿåº¦æœ€å¿«ä¸”é˜»åŠ›æœ€å°ï¼›Pro æ–‡ç¬”æ›´å¥½ä½†å¯èƒ½è¢«æ‹’ã€‚")
    if st.button("æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("è¾“å…¥å‰§æƒ…æŒ‡ä»¤..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        status_placeholder = st.empty()
        status_placeholder.markdown("æ­£åœ¨æ„æ€ä¸­...")
        
        try:
            # å°è¯•åŠ è½½é€‰ä¸­çš„æ¨¡å‹
            model = get_model(selected_model)
            
            # æ„å»ºå†å²è®°å½•
            history = [
                {"role": m["role"], "parts": [m["content"]]} 
                for m in st.session_state.messages 
                if m["role"] != "system"
            ]
            
            # å‘é€è¯·æ±‚
            chat = model.start_chat(history=history[:-1])
            response = chat.send_message(prompt)
            
            status_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "model", "content": response.text})
            
        except Exception as e:
            status_placeholder.error(f"ç”Ÿæˆå¤±è´¥: {e}\n\nå»ºè®®ï¼šå°è¯•åœ¨ä¾§è¾¹æ åˆ‡æ¢å› Flash æ¨¡å‹ï¼Œé‚£ä¸ªæŠ—æ‹’æ›´å°‘ã€‚")
